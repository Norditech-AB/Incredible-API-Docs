---
title: 'Incredible API Documentation'
description: 'AI that can work — Agentic Automation, models, and integrations'
---

Welcome to Incredible — where we build AI that can work, not just talk.

## Let’s break down Incredible

- **Category dominance**: We focus on “AI that can work.” Others optimize for chatting; we optimize for task completion.
- **The company**: Incredible is a Swedish applied AI lab building Agentic Automation.
- **The value**: AI Agents are the holy grail of automation — potentially allowing anyone to automate complex work.

## The story

While building agentic automation, we innovated in agentic AI and created state‑of‑the‑art agentic models, outperforming typical stacks (tool frameworks, MCPs, etc.) in the metric that matters: task completion rate. We’re releasing these agentic models in the Incredible API.

### Agentic models

- **Incredible Tiny** — Matches Gemini 2.5 Flash intelligence. Outperforms in agentic benchmarks. (internally powered by GPT‑5 Nano)
- **Incredible Small** — Matches Gemini 2.5 Pro intelligence. Outperforms in agentic benchmarks. (internally powered by GLM)
- **Incredible Big** — Matches Claude 4.0 Sonnet intelligence. Outperforms in agentic benchmarks. (internally powered by Claude 4.0 Sonnet)
- **Incredible Huge** — Exceeds Claude 4.1 Opus and GPT‑5 in agentic benchmarks. (internally powered by GPT‑5)

> We optimize for task completion — solving real‑world problems — not classroom tests.

## What makes it work (differentiators)

**Others**
- Text as reasoning: produce more tokens before acting
- Text as action: single function calls via tool bridges
- Raw text inputs: emails/transactions as unstructured blobs
- Heavy truncation: context limits block real work

**Us**
- **Code as reasoning**: the model mixes foundational text reasoning with on‑demand live code analysis
- **Code as action**: the model writes code to take action, call APIs, and reference data
- **Intelligent truncation**: abstract representations (summaries, structure, snippets) to preserve breadth
- **Self‑maintaining memory**: the model manages its own memory via code to deep‑dive large datasets

## What this changes

- From single actions to thousands in parallel (e.g., add 1 row vs 1,000 rows)
- Data‑driven work without hallucination (use data, don’t invent it)
- Effective 1B+ context via structured retrieval and memory
- Long tasks stay on track; the agent retains objectives and state

Additional value:
- Lower cost for data‑heavy tasks
- Direct API connections
- Drop‑in replacement for OpenAI/Anthropic APIs (switch in a few lines)
- Price + tool‑use performance advantage → rapid adoption

> Incredible models are optimized for tool use and function calling. For pure chat or creative writing, use traditional LLMs. For getting actual work done with tools and APIs, we’re 10× better.

## Get started

<Card title="Quickstart" icon="rocket" href="/quickstart">
  Create your first agent or call the chat API in minutes.
</Card>

<Card title="Chat Completion" icon="comment" href="/api-reference/chat/completion">
  Core endpoint — non‑streaming and streaming.
</Card>

<Card title="Integrations" icon="plug" href="/api-reference/endpoint/list-integrations">
  Available services and features.
</Card>
