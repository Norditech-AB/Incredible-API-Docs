---
title: "Conversation"
description: "Multi-turn conversation endpoint. Fast and cost-effective for conversational tasks without tool calling."
---

<a href="https://platform.incredible.one/settings/api-keys" target="_blank" style={{ textDecoration: 'none' }}>
  <div style={{ 
    border: '1px solid #e5e7eb', 
    borderRadius: '12px', 
    padding: '20px', 
    margin: '24px 0', 
    display: 'flex', 
    alignItems: 'center', 
    gap: '16px',
    cursor: 'pointer',
    transition: 'all 0.2s'
  }}>
    <div style={{ fontSize: '32px' }}>ðŸ”‘</div>
    <div style={{ flex: 1 }}>
      <div style={{ fontSize: '18px', fontWeight: '600', marginBottom: '4px' }}>Get your Incredible API key</div>
      <div style={{ fontSize: '14px', color: '#6b7280' }}>Generate your API key to start using this endpoint</div>
    </div>
    <div style={{ fontSize: '20px', color: '#9ca3af' }}>â†’</div>
  </div>
</a>

## Overview

The Conversation API is designed for multi-turn dialogues where context and conversation history matter. Unlike the Answer API which handles single questions, Conversation maintains the flow of discussion across multiple exchanges, making it ideal for chatbots, virtual assistants, and interactive applications.

**Key characteristics:**
- **Stateless but context-aware** - You provide the full conversation history with each request
- **Optimized for dialogue** - Faster and more cost-effective than the Agent endpoint when you don't need tool calling
- **Flexible context** - Supports alternating user and assistant messages
- **Document-aware** - Can reference uploaded files for context-rich conversations

**When to use Conversation vs other endpoints:**
- Use **Conversation** for multi-turn dialogue without needing tools or function calling
- Use **Answer** for single-question scenarios or stateless Q&A
- Use **Agent** when you need autonomous tool calling and complex workflows

## Using Conversation

The Conversation endpoint is designed for multi-turn dialogues where you maintain conversation context across exchanges. You send the full message history with each request, and the API generates contextually aware responses. This gives you complete control over conversation management, allowing features like context pruning or conversation forking.

## Examples

<CodeGroup>

```python Python SDK
from incredible_python import Incredible

client = Incredible(api_key="YOUR_API_KEY")

response = client.conversation(
    messages=[
        {"role": "user", "content": "Hello!"},
        {"role": "assistant", "content": "Hi there! How can I help you today?"},
        {"role": "user", "content": "Tell me a joke"}
    ]
)

print(response.response)
```

```ts TypeScript SDK
import { IncredibleClient } from '@incredible-ai/sdk';

const client = new IncredibleClient();

const response = await client.conversation({
  messages: [
    { role: 'user', content: 'Hello!' },
    { role: 'assistant', content: 'Hi there!' },
    { role: 'user', content: 'How are you?' }
  ]
});

console.log(response.response || response.message);
```

```bash cURL
curl -X POST "https://api.incredible.one/v1/conversation" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello!"},
      {"role": "assistant", "content": "Hi there!"},
      {"role": "user", "content": "How are you?"}
    ]
  }'
```

</CodeGroup>

**What are messages?** An array of message objects representing the conversation history. Each message has a `role` (either "user" or "assistant") and `content`. Messages are processed in order, allowing the model to understand the full context of the conversation.

**Best practices:**
- Always provide enough context for the model to understand the current query
- Consider implementing conversation summarization for very long dialogues
- Alternate between user and assistant messages naturally
- Don't include messages that are no longer relevant to the current topic

**Optional: System Prompts** - You can include a `system_prompt` to define the AI's behavior, personality, and constraints. For example: `"You are a helpful customer service representative for Acme Corp."` or `"You are a technical expert who explains concepts in simple terms."` The system prompt shapes the assistant's tone and expertise level throughout the conversation.

**Optional: Streaming** - Set `stream: true` to receive responses in real-time as they're generated. See the Streaming section below for details.

## Attaching Files to Conversations

Files can be attached to individual messages within a conversation, allowing the AI to reference document content when generating responses. This is powerful for document Q&A, report analysis, and context-specific assistance.

You can provide document context in conversations by uploading files and referencing them:

<CodeGroup>

```python Python SDK
from incredible_python import Incredible

client = Incredible(api_key="YOUR_API_KEY")

# Upload a file
with open("report.pdf", "rb") as f:
    file = client.files.upload(file=f, purpose="assistants")

# Use the file in a conversation
response = client.conversation(
    messages=[
        {"role": "user", "content": "What's in this document?", "file_ids": [file.id]},
        {"role": "assistant", "content": "This document contains a quarterly financial report."},
        {"role": "user", "content": "What were the key findings?"}
    ]
)

print(response.response)
```

```ts TypeScript SDK
import { IncredibleClient } from '@incredible-ai/sdk';
import fs from 'fs';

const client = new IncredibleClient({ apiKey: "YOUR_API_KEY" });

// Upload a file
const fileStream = fs.createReadStream('report.pdf');
const file = await client.files.upload({
  file: fileStream,
  purpose: 'assistants'
});

// Use the file in a conversation
const response = await client.conversation({
  messages: [
    { role: 'user', content: "What's in this document?", file_ids: [file.id] },
    { role: 'assistant', content: 'This document contains a quarterly financial report.' },
    { role: 'user', content: 'What were the key findings?' }
  ]
});

console.log(response.response);
```

```bash cURL
# Step 1: Request upload URL
curl -X POST "https://api.incredible.one/v1/files/upload-url" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"filename": "report.pdf"}'

# Step 2: Upload file to returned upload_url
curl -X PUT "UPLOAD_URL_FROM_STEP_1" \
  -H "Content-Type: application/pdf" \
  --data-binary @report.pdf

# Step 3: Confirm upload
curl -X POST "https://api.incredible.one/v1/files/confirm-upload" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "file_id": "FILE_ID_FROM_STEP_1",
    "filename": "report.pdf",
    "file_size": 12345
  }'

# Step 4: Use file in conversation
curl -X POST "https://api.incredible.one/v1/conversation" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "What'\''s in this document?", "file_ids": ["FILE_ID_FROM_STEP_1"]},
      {"role": "assistant", "content": "This document contains a quarterly financial report."},
      {"role": "user", "content": "What were the key findings?"}
    ]
  }'
```

</CodeGroup>

## Streaming Responses

Streaming creates a more natural, chat-like experience by delivering responses in real-time as they're generated. Instead of waiting for the complete message, your users see text appearing progressively, similar to how a human types.

**Benefits of streaming in conversations:**
- **Reduced perceived latency** - Users see progress immediately
- **Better engagement** - The typing effect feels more natural and interactive  
- **Improved UX** - Users can start reading while the response is still being generated
- **Cancellation support** - Users can interrupt long responses they don't need

Enable streaming by setting `stream: true` in your request:

<CodeGroup>

```python Python SDK
from incredible_python import Incredible

client = Incredible(api_key="YOUR_API_KEY")

# Stream a conversation
stream = client.conversation(
    messages=[
        {"role": "user", "content": "Tell me a story about a robot"},
        {"role": "assistant", "content": "Once upon a time..."},
        {"role": "user", "content": "What happened next?"}
    ],
    stream=True
)

# Process streaming chunks
for chunk in stream:
    if hasattr(chunk, 'content') and chunk.content:
        print(chunk.content, end='', flush=True)
    if hasattr(chunk, 'done') and chunk.done:
        print("\n[Stream complete]")
```

```ts TypeScript SDK
import { IncredibleClient } from '@incredible-ai/sdk';

const client = new IncredibleClient({ apiKey: "YOUR_API_KEY" });

// Stream a conversation
const stream = await client.conversation({
  messages: [
    { role: 'user', content: 'Tell me a story about a robot' },
    { role: 'assistant', content: 'Once upon a time...' },
    { role: 'user', content: 'What happened next?' }
  ],
  stream: true
});

// Process streaming events
for await (const event of stream) {
  if (event.content) {
    process.stdout.write(event.content);
  }
  if (event.done) {
    console.log('\n[Stream complete]');
  }
}
```

```bash cURL
curl -X POST "https://api.incredible.one/v1/conversation" \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Tell me a story about a robot"},
      {"role": "assistant", "content": "Once upon a time..."},
      {"role": "user", "content": "What happened next?"}
    ],
    "stream": true
  }'
```

</CodeGroup>

**Stream Event Types:**
- `content` - Text chunks as they're generated
- `thinking` - Internal reasoning process (if available)
- `done` - Signals completion of the stream
- `error` - Any errors that occurred during generation

## Response

```json
{
  "success": true,
  "response": "I'm doing well, thank you for asking! How can I help you today?"
}
```
